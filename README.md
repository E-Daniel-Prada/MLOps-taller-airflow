# MLAIRFLOW

Un proyecto de Machine Learning con Airflow, API, MySQL y procesamiento de datos.

## ğŸ“‚ Estructura del Proyecto

```
MLAIRFLOW/
â”‚â”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ ml_pipeline.py  # DAG de Airflow para el pipeline de ML
â”‚   â”œâ”€â”€ dockerfile          # Contenedor de Airflow
â”‚   â””â”€â”€ requirements.txt    # Dependencias de Airflow
â”‚
â”‚â”€â”€ airflow_logs/scheduler/
â”‚   â”œâ”€â”€ 2025-03-07/         # Logs del scheduler de Airflow
â”‚   â””â”€â”€ latest              # Ãšltimo log del scheduler
â”‚
â”‚â”€â”€ api/
â”‚   â”œâ”€â”€ __pycache__/        # CachÃ© de Python
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ penguin_model.pkl  # Modelo entrenado en formato Pickle
â”‚   â”œâ”€â”€ deploy.py           # Script de despliegue de la API
â”‚   â”œâ”€â”€ dockerfile          # Contenedor de la API
â”‚   â”œâ”€â”€ main.py             # CÃ³digo principal de la API
â”‚   â””â”€â”€ requirements.txt    # Dependencias de la API
â”‚
â”‚â”€â”€ env/                    # ConfiguraciÃ³n de entorno
â”‚
â”‚â”€â”€ mysql/
â”‚   â””â”€â”€ init.sql            # Script de inicializaciÃ³n de MySQL
â”‚
â”‚â”€â”€ preprocess/
â”‚   â”œâ”€â”€ clear_db.py         # Limpieza de la base de datos
â”‚   â”œâ”€â”€ dockerfile          # Contenedor de preprocesamiento
â”‚   â”œâ”€â”€ load_penguins.py    # Carga de datos
â”‚   â”œâ”€â”€ preprocess.py       # Preprocesamiento de datos
â”‚   â””â”€â”€ requirements.txt    # Dependencias de preprocesamiento
â”‚
â”‚â”€â”€ train/
â”‚   â”œâ”€â”€ models/             # Carpeta de modelos entrenados
â”‚   â”œâ”€â”€ dockerfile          # Contenedor del entrenamiento
â”‚   â”œâ”€â”€ requirements.txt    # Dependencias del entrenamiento
â”‚   â”œâ”€â”€ train.py            # Script de entrenamiento del modelo
â”‚
â””â”€â”€ .env                    # Variables de entorno
```

---

## ğŸš€ InstalaciÃ³n

1. Clona el repositorio:
   ```bash
   git clone <URL_DEL_REPO>
   cd MLAIRFLOW
   ```

2. Configura las variables de entorno:
   ```bash
   cp .env.example .env
   ```

3. Construye los contenedores Docker:
   ```bash
   docker-compose up --build
   ```

---

## ğŸ› ï¸ Componentes Principales

### 1ï¸âƒ£ **Airflow**
- Ejecuta y gestiona pipelines de ML.
- DAG principal: `ml_pipeline.py`.

### 2ï¸âƒ£ **API**
- Sirve el modelo entrenado `penguin_model.pkl`.
- Despliegue en `deploy.py`.

### 3ï¸âƒ£ **Base de Datos (MySQL)**
- Base de datos para almacenamiento de datos procesados.
- Script de inicializaciÃ³n: `init.sql`.

### 4ï¸âƒ£ **Preprocesamiento**
- `preprocess.py`: Limpieza y transformaciÃ³n de datos.
- `load_penguins.py`: Carga de datos.

### 5ï¸âƒ£ **Entrenamiento**
- `train.py`: Entrena el modelo de ML.
- Modelos guardados en `train/models/`.

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la licencia [MIT](LICENSE).

---
